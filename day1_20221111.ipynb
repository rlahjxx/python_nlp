{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df92c076",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f6f3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e4e52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ab9191c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d0714c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape = (20, 1), name = 'input')\n",
    "outputs = tf.keras.layers.Dense(units = 10, activation = 'softmax', name = 'output_softmax')(inputs)\n",
    "\n",
    "model_1 = tf.keras.Model(inputs = inputs, outputs = outputs)\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34215434",
   "metadata": {},
   "outputs": [],
   "source": [
    "## hidden\n",
    "Input_size = 20\n",
    "inputs = tf.keras.layers.Input(shape = Input_size, name = 'input')\n",
    "hidden1 = tf.keras.layers.Dense(units = 10, activation='relu', name = 'hidden1')(inputs)\n",
    "outputs = tf.keras.layers.Dense(units = 2, activation = 'softmax', name = 'output')(hidden1)\n",
    "\n",
    "model_2 = tf.keras.Model(inputs = inputs, outputs = outputs)\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfa5522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropout\n",
    "INPUT_SIZE = 20\n",
    "inputs = tf.keras.layers.Input(shape = INPUT_SIZE, name = 'input')\n",
    "dropout = tf.keras.layers.Dropout(rate = 0.2, name = 'dropout')(inputs)\n",
    "hidden = tf.keras.layers.Dense(units = 10, activation = 'relu', name = 'hidden')(dropout)\n",
    "outputs = tf.keras.layers.Dense(units = 2, activation = 'softmax', name = 'output')(hidden)\n",
    "\n",
    "model_3 = tf.keras.Model(inputs = inputs, outputs =outputs)\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e570da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ID convolution l\n",
    "INPUT_SIZE = (20, 1)\n",
    "inputs = tf.keras.Input(shape = INPUT_SIZE)\n",
    "conv = tf.keras.layers.Conv1D(filters = 10, kernel_size = 3, padding = 'same', activation = 'relu')(inputs)\n",
    "model4 = tf.keras.Model(inputs = inputs, outputs = conv)\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f76151e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape = (20, 1), name = 'input')\n",
    "dropout = tf.keras.layers.Dropout(rate = 0.2, name = 'dropout')(inputs)\n",
    "conv = tf.keras.layers.Conv1D(filters = 10,\n",
    "                             kernel_size = 3,\n",
    "                             padding = 'same', # 원래 shape 개수와 같게 만들어줌\n",
    "                             activation = 'relu',\n",
    "                             name = 'Conv')(dropout)\n",
    "max_pool = tf.keras.layers.MaxPool1D(pool_size = 3)(conv)\n",
    "flatten = tf.keras.layers.Flatten()(max_pool)\n",
    "hidden = tf.keras.layers.Dense(units = 50, activation = 'relu', name = 'hidden')(flatten)\n",
    "outputs = tf.keras.layers.Dense(units = 10, activation = 'softmax')(hidden)\n",
    "\n",
    "model_functionAPI = tf.keras.Model(inputs = inputs, outputs = outputs, name = 'functionAPI')\n",
    "model_functionAPI.summary()\n",
    "\n",
    "# kernel 1 => 파라미터 1개를 가지기 때문에, kernel이 3인 경우 파라미터는 3개가 된다.\n",
    "# 10 (filter의 개수) * 3 (kernel 개수) + 10 (filter 1개 당 bias 파라미터 1개 -> filter가 10개이므로, 필요 bias 파라미터 = 10개)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58eface",
   "metadata": {},
   "source": [
    "# Model 구축"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bb5ce7",
   "metadata": {},
   "source": [
    "### Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a093d08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential(name = 'Sequential_API')\n",
    "model.add(tf.keras.layers.Input(shape = (32, ), name = 'input'))\n",
    "model.add(tf.keras.layers.Dense(units = 64, activation = 'relu', name = 'Dense1'))\n",
    "model.add(tf.keras.layers.Dense(units = 64, activation = 'relu', name = 'Dense2'))\n",
    "model.add(tf.keras.layers.Dense(units = 10, activation = 'softmax', name ='Outputs'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1555f3d8",
   "metadata": {},
   "source": [
    "### Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb3a547",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape = (32, ), name = 'input')\n",
    "Dense1 = tf.keras.layers.Dense(units = 64, activation = 'relu', name = 'dense1')(inputs)\n",
    "Dense2 = tf.keras.layers.Dense(units = 64, activation = 'relu', name = 'dense2')(Dense1)\n",
    "outputs = tf.keras.layers.Dense(units = 10, activation = 'softmax', name = 'outputs')(Dense2)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4849cb3c",
   "metadata": {},
   "source": [
    "### Custom layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e5715f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Customlayer(tf.keras.layers.Layer) :\n",
    "    def __init__(self, hidden1, hidden2, output_layer) :\n",
    "        super(Customlayer, self).__init__()\n",
    "        self.hidden1 = hidden1\n",
    "        self.hidden2 = hidden2\n",
    "        self.output_layer = output_layer\n",
    "\n",
    "    def build(self, inputs) :\n",
    "        self.dense_layer1 = tf.keras.layers.Dense(units = self.hidden1, activation = 'relu', name = 'Dense1')\n",
    "        self.dense_layer2 = tf.keras.layers.Dense(units = self.hidden2, activation = 'relu', name = 'Dense2')\n",
    "        self.output_layers = tf.keras.layers.Dense(units = self.output_layer, activation = 'softmax', name = 'output')\n",
    "\n",
    "    def call(self, inputs) :\n",
    "        x = self.dense_layer1(inputs)\n",
    "        x = self.dense_layer2(x)\n",
    "\n",
    "        return self.output_layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b04a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential(name = 'Custom_layer')\n",
    "model.add(tf.keras.layers.Input(shape = (32, )))\n",
    "model.add(Customlayer(64, 64, 10))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3109aea2",
   "metadata": {},
   "source": [
    "### Subclassing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2d31c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model) :\n",
    "    def __init__(self, hidden1, hidden2, output_layers) :\n",
    "        super(MyModel, self).__init__(name = 'MyModel')\n",
    "        self.dense1 = tf.keras.layers.Dense(units = hidden1, activation = 'relu', name = 'dense1')\n",
    "        self.dense2 = tf.keras.layers.Dense(units = hidden2, activation = 'relu', name = 'dense2')\n",
    "        self.outputlayer = tf.keras.layers.Dense(units = output_layers, activation='softmax', name = 'output_layer')\n",
    "        \n",
    "    def call(self, inputs) :\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dense2(x)\n",
    "        \n",
    "        return self.output_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab7fea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sub = MyModel(64,64,10)\n",
    "\n",
    "# model_sub.summary()\n",
    "\n",
    "model_sub.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "model_sub.fit(train_input, train_target, epochs = 20, batch_size = 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620c42f1",
   "metadata": {},
   "source": [
    "# 데이터 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "baf0a25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57d0d9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    }
   ],
   "source": [
    "dataset = np.loadtxt('./pima-indians-diabetes.csv', delimiter = ',')\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac7865ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6.    148.     72.    ...  33.6     0.627  50.   ]\n",
      " [  1.     85.     66.    ...  26.6     0.351  31.   ]\n",
      " [  8.    183.     64.    ...  23.3     0.672  32.   ]\n",
      " ...\n",
      " [  5.    121.     72.    ...  26.2     0.245  30.   ]\n",
      " [  1.    126.     60.    ...  30.1     0.349  47.   ]\n",
      " [  1.     93.     70.    ...  30.4     0.315  23.   ]]\n",
      "[1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0.\n",
      " 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0.\n",
      " 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1.\n",
      " 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0.\n",
      " 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
      " 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0.\n",
      " 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1.\n",
      " 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0.\n",
      " 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
      " 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0.\n",
      " 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1.\n",
      " 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1.\n",
      " 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1.\n",
      " 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "X = dataset[:, 0 : 8]\n",
    "Y = dataset[:, -1]\n",
    "\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8195069c",
   "metadata": {},
   "source": [
    "### Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97cfdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential(name = 'Sequential')\n",
    "model.add(tf.keras.layers.Input(shape = (8, ), name = 'input'))\n",
    "model.add(tf.keras.layers.Dense(units = 12, activation = 'relu', name = 'dense1'))\n",
    "model.add(tf.keras.layers.Dense(units = 8, activation = 'relu', name = 'dense2'))\n",
    "model.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid', name = 'output'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdee05f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy', \n",
    "             optimizer = 'adam', metrics = ['acc'])\n",
    "model.fit(X, Y, epochs = 100, batch_size = 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556bd2c0",
   "metadata": {},
   "source": [
    "### functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e680151",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape = (8, ), name = 'input')\n",
    "dense1 = tf.keras.layers.Dense(units = 12, activation = 'relu', name = 'dense1')(inputs)\n",
    "dense2 = tf.keras.layers.Dense(units = 8, activation = 'relu', name = 'dense2')(dense1)\n",
    "outputs = tf.keras.layers.Dense(units = 1, activation = 'sigmoid', name = 'output')(dense2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ff5622",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy', \n",
    "             optimizer = 'adam', metrics = ['acc'])\n",
    "model.fit(X, Y, epochs = 100, batch_size = 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745ccb9f",
   "metadata": {},
   "source": [
    "### Subclassing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5fbad63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mymodel(tf.keras.Model) :\n",
    "    def __init__(self, hidden1, hidden2, outputs) :\n",
    "        super(Mymodel, self).__init__()\n",
    "        self.dense1 = tf.keras.layers.Dense(units = hidden1, activation = tf.nn.relu, name = 'dense1')\n",
    "        self.dense2 = tf.keras.layers.Dense(units = hidden2, activation = tf.nn.relu, name = 'dense2')\n",
    "        self.outputs = tf.keras.layers.Dense(units = outputs, activation = tf.nn.sigmoid, name = 'output')\n",
    "        \n",
    "    def call(self, inputs) :\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dense2(x)\n",
    "        \n",
    "        return self.outputs(x)\n",
    "\n",
    "model_sub = Mymodel(12, 8, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d65e7ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath = './model_save/{epoch:2d}_{val_loss:.4f}.hdf5', monitor = 'var_loss',\n",
    "                                               verbose = 1, save_best_only = True, save_weights_only = True)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e75e5a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 [==============================] - 1s 31ms/step - loss: 6.6035 - acc: 0.6547 - val_loss: 4.9366 - val_acc: 0.6429\n",
      "WARNING:tensorflow:Can save best model only with var_loss available, skipping.\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 5.4071 - acc: 0.5782 - val_loss: 4.5167 - val_acc: 0.5584\n",
      "WARNING:tensorflow:Can save best model only with var_loss available, skipping.\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 4.9148 - acc: 0.5342 - val_loss: 3.9847 - val_acc: 0.5779\n",
      "WARNING:tensorflow:Can save best model only with var_loss available, skipping.\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 4.3022 - acc: 0.5945 - val_loss: 3.5581 - val_acc: 0.6169\n",
      "WARNING:tensorflow:Can save best model only with var_loss available, skipping.\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 3.8440 - acc: 0.6515 - val_loss: 3.2201 - val_acc: 0.6429\n",
      "WARNING:tensorflow:Can save best model only with var_loss available, skipping.\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 3.4353 - acc: 0.6466 - val_loss: 2.8724 - val_acc: 0.6364\n",
      "WARNING:tensorflow:Can save best model only with var_loss available, skipping.\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 3.0217 - acc: 0.6319 - val_loss: 2.5127 - val_acc: 0.6299\n",
      "WARNING:tensorflow:Can save best model only with var_loss available, skipping.\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2.5911 - acc: 0.6189 - val_loss: 2.1190 - val_acc: 0.6104\n",
      "WARNING:tensorflow:Can save best model only with var_loss available, skipping.\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2.1342 - acc: 0.6124 - val_loss: 1.7008 - val_acc: 0.6169\n",
      "WARNING:tensorflow:Can save best model only with var_loss available, skipping.\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.6596 - acc: 0.6173 - val_loss: 1.3094 - val_acc: 0.6104\n",
      "WARNING:tensorflow:Can save best model only with var_loss available, skipping.\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 1.2175 - acc: 0.6336 - val_loss: 0.9597 - val_acc: 0.6169\n",
      "WARNING:tensorflow:Can save best model only with var_loss available, skipping.\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.8668 - acc: 0.6319 - val_loss: 0.7985 - val_acc: 0.5974\n",
      "WARNING:tensorflow:Can save best model only with var_loss available, skipping.\n",
      "Epoch 13/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.7499 - acc: 0.6303 - val_loss: 0.8308 - val_acc: 0.5325\n",
      "WARNING:tensorflow:Can save best model only with var_loss available, skipping.\n",
      "Epoch 14/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.7204 - acc: 0.6596 - val_loss: 0.7758 - val_acc: 0.5455\n",
      "WARNING:tensorflow:Can save best model only with var_loss available, skipping.\n",
      "Epoch 15/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6804 - acc: 0.6596 - val_loss: 0.6991 - val_acc: 0.5584\n",
      "WARNING:tensorflow:Can save best model only with var_loss available, skipping.\n",
      "Epoch 16/100\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.6622 - acc: 0.6433 - val_loss: 0.6754 - val_acc: 0.6039\n",
      "WARNING:tensorflow:Can save best model only with var_loss available, skipping.\n",
      "Epoch 17/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6552 - acc: 0.6384 - val_loss: 0.6715 - val_acc: 0.6039\n",
      "WARNING:tensorflow:Can save best model only with var_loss available, skipping.\n",
      "Epoch 18/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6467 - acc: 0.6547 - val_loss: 0.6769 - val_acc: 0.5519\n",
      "WARNING:tensorflow:Can save best model only with var_loss available, skipping.\n",
      "Epoch 19/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6448 - acc: 0.6661 - val_loss: 0.6759 - val_acc: 0.5584\n",
      "WARNING:tensorflow:Can save best model only with var_loss available, skipping.\n",
      "Epoch 20/100\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.6392 - acc: 0.6580 - val_loss: 0.6601 - val_acc: 0.5584\n",
      "WARNING:tensorflow:Can save best model only with var_loss available, skipping.\n",
      "Epoch 21/100\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6349 - acc: 0.6417 - val_loss: 0.6626 - val_acc: 0.6039\n",
      "WARNING:tensorflow:Can save best model only with var_loss available, skipping.\n",
      "Epoch 22/100\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.6346 - acc: 0.6531 - val_loss: 0.6527 - val_acc: 0.5649\n",
      "WARNING:tensorflow:Can save best model only with var_loss available, skipping.\n",
      "Epoch 23/100\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.6251 - acc: 0.6629 - val_loss: 0.6539 - val_acc: 0.5779\n",
      "WARNING:tensorflow:Can save best model only with var_loss available, skipping.\n",
      "Epoch 24/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6239 - acc: 0.6515 - val_loss: 0.6481 - val_acc: 0.6234\n",
      "WARNING:tensorflow:Can save best model only with var_loss available, skipping.\n",
      "Epoch 25/100\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.6186 - acc: 0.6531 - val_loss: 0.6433 - val_acc: 0.6039\n",
      "WARNING:tensorflow:Can save best model only with var_loss available, skipping.\n",
      "Epoch 26/100\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6163 - acc: 0.6596 - val_loss: 0.6361 - val_acc: 0.6299\n",
      "WARNING:tensorflow:Can save best model only with var_loss available, skipping.\n",
      "Epoch 27/100\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.6133 - acc: 0.6564 - val_loss: 0.6350 - val_acc: 0.6364\n",
      "WARNING:tensorflow:Can save best model only with var_loss available, skipping.\n",
      "Epoch 28/100\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6100 - acc: 0.6580 - val_loss: 0.6351 - val_acc: 0.6104\n",
      "WARNING:tensorflow:Can save best model only with var_loss available, skipping.\n",
      "Epoch 29/100\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6068 - acc: 0.6629 - val_loss: 0.6321 - val_acc: 0.6429\n",
      "WARNING:tensorflow:Can save best model only with var_loss available, skipping.\n",
      "Epoch 30/100\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.6063 - acc: 0.6482 - val_loss: 0.6205 - val_acc: 0.6688\n",
      "WARNING:tensorflow:Can save best model only with var_loss available, skipping.\n",
      "Epoch 31/100\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.6072 - acc: 0.6547 - val_loss: 0.6242 - val_acc: 0.6688\n",
      "WARNING:tensorflow:Can save best model only with var_loss available, skipping.\n",
      "Epoch 32/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6028 - acc: 0.6678 - val_loss: 0.6194 - val_acc: 0.6429\n",
      "WARNING:tensorflow:Can save best model only with var_loss available, skipping.\n",
      "Epoch 33/100\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.6039 - acc: 0.6596 - val_loss: 0.6291 - val_acc: 0.6623\n",
      "WARNING:tensorflow:Can save best model only with var_loss available, skipping.\n",
      "Epoch 34/100\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5977 - acc: 0.6564 - val_loss: 0.6143 - val_acc: 0.6818\n",
      "WARNING:tensorflow:Can save best model only with var_loss available, skipping.\n",
      "Epoch 35/100\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5957 - acc: 0.6596 - val_loss: 0.6200 - val_acc: 0.6688\n",
      "WARNING:tensorflow:Can save best model only with var_loss available, skipping.\n",
      "Epoch 36/100\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.5949 - acc: 0.6645 - val_loss: 0.6150 - val_acc: 0.6948\n",
      "WARNING:tensorflow:Can save best model only with var_loss available, skipping.\n",
      "Epoch 37/100\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5940 - acc: 0.6661 - val_loss: 0.6173 - val_acc: 0.6753\n",
      "WARNING:tensorflow:Can save best model only with var_loss available, skipping.\n",
      "Epoch 38/100\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5917 - acc: 0.6775 - val_loss: 0.6143 - val_acc: 0.6688\n",
      "WARNING:tensorflow:Can save best model only with var_loss available, skipping.\n",
      "Epoch 39/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5952 - acc: 0.6612 - val_loss: 0.6298 - val_acc: 0.6688\n",
      "WARNING:tensorflow:Can save best model only with var_loss available, skipping.\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5891 - acc: 0.6661 - val_loss: 0.6043 - val_acc: 0.6688\n",
      "WARNING:tensorflow:Can save best model only with var_loss available, skipping.\n",
      "Epoch 41/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5877 - acc: 0.6808 - val_loss: 0.6094 - val_acc: 0.7013\n",
      "WARNING:tensorflow:Can save best model only with var_loss available, skipping.\n",
      "Epoch 42/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5853 - acc: 0.6743 - val_loss: 0.6054 - val_acc: 0.6818\n",
      "WARNING:tensorflow:Can save best model only with var_loss available, skipping.\n",
      "Epoch 43/100\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5853 - acc: 0.6775 - val_loss: 0.6191 - val_acc: 0.6104\n",
      "WARNING:tensorflow:Can save best model only with var_loss available, skipping.\n",
      "Epoch 44/100\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5795 - acc: 0.6792 - val_loss: 0.6041 - val_acc: 0.6688\n",
      "WARNING:tensorflow:Can save best model only with var_loss available, skipping.\n",
      "Epoch 45/100\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5789 - acc: 0.6726 - val_loss: 0.6118 - val_acc: 0.6688\n",
      "WARNING:tensorflow:Can save best model only with var_loss available, skipping.\n",
      "Epoch 46/100\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5760 - acc: 0.6759 - val_loss: 0.6073 - val_acc: 0.6753\n",
      "WARNING:tensorflow:Can save best model only with var_loss available, skipping.\n",
      "Epoch 47/100\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5783 - acc: 0.6840 - val_loss: 0.6140 - val_acc: 0.6883\n",
      "WARNING:tensorflow:Can save best model only with var_loss available, skipping.\n",
      "Epoch 48/100\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5723 - acc: 0.6938 - val_loss: 0.6134 - val_acc: 0.6299\n",
      "WARNING:tensorflow:Can save best model only with var_loss available, skipping.\n",
      "Epoch 49/100\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5737 - acc: 0.6873 - val_loss: 0.6163 - val_acc: 0.6234\n",
      "WARNING:tensorflow:Can save best model only with var_loss available, skipping.\n",
      "Epoch 50/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5785 - acc: 0.6922 - val_loss: 0.6091 - val_acc: 0.6883\n",
      "WARNING:tensorflow:Can save best model only with var_loss available, skipping.\n",
      "Epoch 51/100\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5709 - acc: 0.6808 - val_loss: 0.6302 - val_acc: 0.6688\n",
      "WARNING:tensorflow:Can save best model only with var_loss available, skipping.\n",
      "Epoch 52/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5709 - acc: 0.6922 - val_loss: 0.6067 - val_acc: 0.6494\n",
      "WARNING:tensorflow:Can save best model only with var_loss available, skipping.\n",
      "Epoch 53/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5672 - acc: 0.6889 - val_loss: 0.6200 - val_acc: 0.6688\n",
      "WARNING:tensorflow:Can save best model only with var_loss available, skipping.\n",
      "Epoch 54/100\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5675 - acc: 0.6971 - val_loss: 0.6203 - val_acc: 0.5974\n",
      "WARNING:tensorflow:Can save best model only with var_loss available, skipping.\n"
     ]
    }
   ],
   "source": [
    "model_sub.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['acc'])\n",
    "history = model_sub.fit(X, Y, epochs = 100, batch_size = 70, validation_split = 0.2, callbacks = [checkpoint, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4fa2ebe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.701298713684082"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(history.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5930406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.3.4-cp36-cp36m-win_amd64.whl (8.5 MB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.3.1-cp36-cp36m-win_amd64.whl (51 kB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\programdata\\anaconda3\\envs\\pre_tensorflow\\lib\\site-packages (from matplotlib) (1.19.5)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\programdata\\anaconda3\\envs\\pre_tensorflow\\lib\\site-packages (from matplotlib) (3.0.4)\n",
      "Collecting pillow>=6.2.0\n",
      "  Downloading Pillow-8.4.0-cp36-cp36m-win_amd64.whl (3.2 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\programdata\\anaconda3\\envs\\pre_tensorflow\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\envs\\pre_tensorflow\\lib\\site-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
      "Installing collected packages: pillow, kiwisolver, cycler, matplotlib\n",
      "Successfully installed cycler-0.11.0 kiwisolver-1.3.1 matplotlib-3.3.4 pillow-8.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4898b185",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "46fa2376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['val_loss'], '-r', label = 'Validation loss')\n",
    "plt.plot(history.history['val_acc'], '-b', label = 'Validation acc')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adc0013",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
